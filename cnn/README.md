# Cnn

**TODO: Add description**

## Installation

If [available in Hex](https://hex.pm/docs/publish), the package can be installed
by adding `cnn` to your list of dependencies in `mix.exs`:

```elixir
def deps do
  [
    {:cnn, "~> 0.1.0"}
  ]
end
```

Documentation can be generated with [ExDoc](https://github.com/elixir-lang/ex_doc)
and published on [HexDocs](https://hexdocs.pm). Once published, the docs can
be found at <https://hexdocs.pm/cnn>.


Estrutura dos Arquivos:

lib/cnn.ex - M√≥dulo principal que orquestra toda a aplica√ß√£o
lib/cnn/matrix.ex - Cria√ß√£o e manipula√ß√£o das matrizes 5x5 dos d√≠gitos 0-9
lib/cnn/neural.ex - Implementa√ß√£o da rede neural convolucional
lib/cnn/conv_ops.ex - Opera√ß√µes convolucionais (convolu√ß√£o, pooling, etc.)
lib/cnn/utils.ex - Utilit√°rios para manipula√ß√£o de matrizes e fun√ß√µes matem√°ticas
lib/cnn/application.ex - Aplica√ß√£o OTP com modo interativo e benchmarks
mix.exs - Configura√ß√£o do projeto com CLI integrado

Principais Melhorias:
Arquitetura Elixir:

Modulariza√ß√£o limpa: Cada responsabilidade em seu m√≥dulo
Structs tipados: Para camadas neurais (ConvLayer, FCLayer)
Pattern matching: Uso extensivo para controle de fluxo
Pipes: Para opera√ß√µes funcionais encadeadas
OTP Application: Estrutura padr√£o Elixir

Funcionalidades Mantidas:

‚úÖ CNN completa (2 camadas conv + 2 fully connected)
‚úÖ Classifica√ß√£o de d√≠gitos 0-9 (matrizes 5x5)
‚úÖ Opera√ß√µes de convolu√ß√£o e max pooling
‚úÖ Fun√ß√µes de ativa√ß√£o (ReLU, Softmax)
‚úÖ Teste com ru√≠do
‚úÖ Estat√≠sticas e benchmarks
‚úÖ Modo interativo

Funcionalidades Adicionais:

CLI integrado: Execute como escript (mix escript.build && ./cnn)
Modo interativo: Teste diferentes configura√ß√µes
Benchmark detalhado: Performance de m√∫ltiplas execu√ß√µes
Estat√≠sticas da rede: Contagem de par√¢metros e arquitetura
Utilit√°rios matem√°ticos: Mais fun√ß√µes para ML (dropout, clipping, etc.)

Como Usar:
bash# Compilar
mix compile

# Executar programa principal
mix run -e "Cnn.main()"

# Executar todos os testes
mix run -e "Cnn.run_tests()"

# Testar d√≠gito espec√≠fico
mix run -e "Cnn.test_digit(5)"

# Testar com ru√≠do
mix run -e "Cnn.test_digit(5, 0.2)"

# Modo interativo
mix run -e "Cnn.Application.interactive_mode()"

# Gerar execut√°vel
mix escript.build
./cnn interactive
O


üìä Fluxo de Processos e Dados do Sistema
flowchart TD

%% Entrada
A[Usu√°rio via CLI ou Modo Interativo] -->|comando| B[Cnn.Application / Cnn.CLI]

%% Orquestra√ß√£o
B -->|executa| C[Cnn (M√≥dulo Principal)]

%% Cria√ß√£o de Dados
C --> D[Cnn.Matrix.create_digit_matrices]
D -->|gera| E[Matrizes 5x5 dos d√≠gitos 0‚Äì9]

%% Cria√ß√£o da Rede
C --> F[Cnn.Neural.create_network]
F -->|estruturas| G[Conv1, Conv2, FC1, FC2]

%% Treinamento
C --> H[Cnn.Neural.train_network]
E --> H
H -->|rede treinada| I[Neural Network Treinada]

%% Testes
C --> J[Cnn.Neural.test_network_patterns]
I --> J
E --> J
J -->|Predi√ß√£o e Confian√ßa| K[Resultados dos Testes]

%% Alternativas de Predi√ß√£o
I --> L[Cnn.Neural.predict]
I --> M[Cnn.Neural.predict_with_patterns]

%% Opera√ß√µes de Camadas
L --> N[Cnn.ConvOps]
M --> N
N -->|Conv, Pooling, ReLU| O[Mapas de Caracter√≠sticas]

%% Fun√ß√µes de Apoio
E --> P[Cnn.Utils]
F --> P
H --> P
J --> P
L --> P
M --> P
N --> P

%% Sa√≠da
K --> Q[Sa√≠da no Console: Estat√≠sticas, Benchmarks, Resultados]

üîé Explica√ß√£o por Etapas

Entrada (CLI / Interativo)

O usu√°rio interage via Cnn.CLI (mix escript.build && ./cnn) ou modo interativo (Cnn.Application.interactive_mode).

Possibilidades: rodar main, test_all, test_N, noise_test, benchmark, stats.

Orquestra√ß√£o (Cnn.ex)

Respons√°vel por coordenar:

Cria√ß√£o das matrizes dos d√≠gitos (Matrix).

Cria√ß√£o e inicializa√ß√£o da rede (Neural).

Treinamento (train_network).

Testes (test_network_patterns ou predict).

Estat√≠sticas e benchmarks.

Dados de Entrada (Matrix)

create_digit_matrices/0: gera representa√ß√µes fixas 5x5 para cada d√≠gito (0‚Äì9).

Pode aplicar convers√µes (integer_to_float_matrix/1), normaliza√ß√£o ou ru√≠do.

Cria√ß√£o da Rede (Neural)

Rede definida em structs:

ConvLayer: filtros 3x3 + bias.

FCLayer: pesos + bias.

Inicializa√ß√£o Xavier para pesos.

Treinamento (train_network)

M√©todo baseado em assinaturas de padr√µes (features extra√≠das de cada d√≠gito).

Atualiza biases das camadas totalmente conectadas.

Predi√ß√£o (Neural)

Dois modos:

predict/2: extra√ß√£o estat√≠stica de features + forward em FC1 ‚Üí FC2 ‚Üí Softmax.

predict_with_patterns/3: compara√ß√£o direta com matrizes de treino (similaridade).

Ambos retornam probabilidades para cada d√≠gito.

Opera√ß√µes Convolucionais (ConvOps)

conv_forward/3, convolve_2d/3, max_pool/2.

Aplica√ß√£o de ReLU, padding e stride.

Usado dentro da pipeline para gerar mapas de caracter√≠sticas.

Fun√ß√µes Utilit√°rias (Utils)

Normaliza√ß√£o, dropout, clipping, softmax, estat√≠sticas de matrizes.

Opera√ß√µes matem√°ticas (dot product, matrix multiply, transpose).

Sa√≠da (Console)

Resultados:

Matrizes de d√≠gitos.

Pesos da rede.

Predi√ß√µes com confian√ßa (%).

Estat√≠sticas de acur√°cia.

Benchmarks de tempo (treinamento e infer√™ncia).


üß† Arquitetura da CNN
flowchart TD

%% Entrada
A[Entrada: Matriz 5x5 (25 pixels)] --> B[Conv1: 4 filtros 3x3 + ReLU]

B --> C[Pool1: MaxPooling 2x2]
C --> D[Conv2: 8 filtros 3x3 + ReLU]

D --> E[Pool2: MaxPooling 2x2]
E --> F[Flatten: vetor de caracter√≠sticas (~8 elementos)]

F --> G[FC1: Camada totalmente conectada (16 neur√¥nios, ReLU)]
G --> H[FC2: Camada de sa√≠da (10 neur√¥nios)]

H --> I[Softmax ‚Üí Probabilidades para d√≠gitos 0‚Äì9]

üìê Explica√ß√£o da Arquitetura

Entrada (5x5 = 25 pixels)
Cada d√≠gito √© representado como uma matriz 5x5 de 0 e 1.

Conv1 (4 filtros 3x3 + ReLU)

Gera 4 feature maps 3x3.

Ativa√ß√£o ReLU aplicada a cada sa√≠da.

Pool1 (MaxPooling 2x2)

Reduz cada mapa para dimens√µes menores (compress√£o de informa√ß√£o).

Conv2 (8 filtros 3x3 + ReLU)

Aplica 8 filtros sobre os mapas da Pool1.

Extrai padr√µes mais complexos.

Pool2 (MaxPooling 2x2)

Reduz novamente os mapas.

Sa√≠da pronta para ‚Äúachatar‚Äù.

Flatten

Transforma os mapas resultantes em um vetor 1D (~8 valores).

FC1 (16 neur√¥nios, ReLU)

Primeira camada densa.

Combina as features em representa√ß√µes abstratas.

FC2 (10 neur√¥nios)

Camada final.

Cada neur√¥nio corresponde a um d√≠gito (0‚Äì9).

Softmax

Converte as sa√≠das em probabilidades normalizadas.

Resultado final = d√≠gito mais prov√°vel.